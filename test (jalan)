import cv2
import os

# Load HAAR face classifier
face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + "haarcascade_frontalface_default.xml")

# Function to detect and draw bounding boxes around faces
def detect_bounding_box(vid):
    gray_image = cv2.cvtColor(vid, cv2.COLOR_BGR2GRAY)
    faces = face_classifier.detectMultiScale(gray_image, 1.3, 5, minSize=(40, 40))
    for (x, y, w, h) in faces:
        cv2.rectangle(vid, (x, y), (x + w, y + h), (0, 255, 0), 4)
    return faces

# Function to extract and return the first detected face
def face_extractor(img):
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    faces = face_classifier.detectMultiScale(gray, 1.3, 5)
    
    if len(faces) == 0:
        return None
    
    # Crop the first face found
    for (x, y, w, h) in faces:
        cropped_face = img[y:y + h, x:x + w]
        return cropped_face  # Return the first detected face

# Initialize Webcam
cap = cv2.VideoCapture(1)  # Change to 0 if using the default camera
count = 0

# Create directory if it doesn't exist
output_dir = './iCloud Photos/'
os.makedirs(output_dir, exist_ok=True)

# Collect samples of your face from webcam input
while True:
    ret, frame = cap.read()
    if not ret:
        print("Failed to capture image")
        break

    # Detect faces and draw bounding boxes
    faces = detect_bounding_box(frame)

    # Extract the first detected face
    face = face_extractor(frame)
    
    if face is not None:
        count += 1
        face = cv2.resize(face, (200, 200))
        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)

        # Save file in specified directory with unique name
        file_name_path = os.path.join(output_dir, 'sample' + str(count) + '.jpg')
        cv2.imwrite(file_name_path, face)

        # Put count on images and display live count
        cv2.putText(face, str(count), (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 255, 0), 2)
        cv2.imshow('Face Cropper', face)

    # Display the video frame with bounding boxes
    cv2.imshow("My Face Detection Project", frame)

    # Break if 'q' is pressed or if 100 samples are collected
    if cv2.waitKey(1) & 0xFF == ord("q") or count >= 100:
        break

# Release the video capture and close windows
cap.release()
cv2.destroyAllWindows()
print("Collecting Samples Complete")
